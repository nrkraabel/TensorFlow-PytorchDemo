{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#First Model Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake data\n",
    "train_X = torch.randn(100,1) #random numbers\n",
    "train_Y = 3* train_X + 5 + torch.randn(100,1) * 0.5 #Linear function with limited randomness\n",
    "#function 3* x_train + 5 + randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        self.linear = nn.Linear(1,1) # takes one input produces one output\n",
    "    #In pytorch you write your own forward functions\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Training Loss:32.0713005065918\n",
      "Epoch:10, Training Loss:22.183534622192383\n",
      "Epoch:20, Training Loss:15.401761054992676\n",
      "Epoch:30, Training Loss:10.739148139953613\n",
      "Epoch:40, Training Loss:7.525900840759277\n",
      "Epoch:50, Training Loss:5.306326866149902\n",
      "Epoch:60, Training Loss:3.7696421146392822\n",
      "Epoch:70, Training Loss:2.7033796310424805\n",
      "Epoch:80, Training Loss:1.9619348049163818\n",
      "Epoch:90, Training Loss:1.4452848434448242\n",
      "Epoch:100, Training Loss:1.084554672241211\n",
      "Epoch:110, Training Loss:0.8322069048881531\n",
      "Epoch:120, Training Loss:0.6553540229797363\n",
      "Epoch:130, Training Loss:0.5311945676803589\n",
      "Epoch:140, Training Loss:0.4438852369785309\n"
     ]
    }
   ],
   "source": [
    "#Running the Linear Model (\"Driver Code\")\n",
    "modelFFNN = LinearRegression()\n",
    "lossFn = nn.MSELoss() #common also name criterion\n",
    "optimizer = torch.optim.SGD(modelFFNN.parameters(), lr=0.01)\n",
    "for epoch in range(150):\n",
    "    prediction = modelFFNN(train_X)\n",
    "    loss = lossFn(prediction, train_Y)\n",
    "    optimizer.zero_grad() # you have to zero the gradients \n",
    "    loss.backward() # back propagation \n",
    "    optimizer.step() # Learning step \n",
    "    if epoch %10 == 0:\n",
    "        print(f\"Epoch:{epoch}, Training Loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model function = x * tensor([[2.7393]]) + tensor([4.7431])\n"
     ]
    }
   ],
   "source": [
    "for layer in modelFFNN.children():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        print(f\"Model function = x * {layer.state_dict()['weight']} + {layer.state_dict()['bias']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "#Feed forward Neural Network Classification problem\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "#generating data using SKlearn sample datasets \n",
    "X,Y = make_moons(n_samples=2000, noise=0.1)\n",
    "train_X = torch.tensor(X, dtype=torch.float32)\n",
    "train_Y = torch.tensor(Y, dtype=torch.int64)\n",
    "test_x, test_y = make_moons(n_samples=400, noise=0.1)\n",
    "test_X = torch.tensor(test_x, dtype=torch.float32)\n",
    "test_Y = torch.tensor(test_y, dtype=torch.int64)\n",
    "print(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple FFNN\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self,dimenisonalEmbedding):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(2,dimenisonalEmbedding)\n",
    "        self.layer2 = nn.Linear(dimenisonalEmbedding,2)\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        return self.layer2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Training Loss:0.6759788990020752\n",
      "Epoch:100, Training Loss:0.021177159622311592\n",
      "Epoch:200, Training Loss:0.00737897539511323\n",
      "Epoch:300, Training Loss:0.004268783610314131\n",
      "Epoch:400, Training Loss:0.0029220113065093756\n",
      "Epoch:500, Training Loss:0.002167722675949335\n",
      "Epoch:600, Training Loss:0.0017013741889968514\n",
      "Epoch:700, Training Loss:0.0013849803945049644\n",
      "Epoch:800, Training Loss:0.00115487992297858\n",
      "Epoch:900, Training Loss:0.000980548677034676\n"
     ]
    }
   ],
   "source": [
    "modelFFNN = FFNN(100)\n",
    "lossFnCE = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelFFNN.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    prediction = modelFFNN(train_X)\n",
    "    loss = lossFnCE(prediction, train_Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch %100 == 0:\n",
    "        print(f\"Epoch:{epoch}, Training Loss:{loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss = 0.0030432736966758966\n"
     ]
    }
   ],
   "source": [
    "predictionTest = modelFFNN(test_X)\n",
    "testLoss = lossFnCE(predictionTest, test_Y)\n",
    "print(f\"Testing loss = {testLoss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "35.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.fc1 = nn.Linear(16*26*26, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = x.view(-1, 16*26*26)\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, training loss = 0.032170966267585754\n",
      "epoch 1, training loss = 0.011517233215272427\n",
      "epoch 2, training loss = 0.07380864769220352\n",
      "epoch 3, training loss = 0.18718363344669342\n",
      "epoch 4, training loss = 0.017924603074789047\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "lossFnCE = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for images, labels in train_loader:\n",
    "        prediction = model(images)\n",
    "        loss = lossFnCE(prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch {epoch+1}, training loss = {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
